# -*- coding: utf-8 -*-
"""Dog or Cats CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qBa3E3go9mYFX2AUEqs7M_F8CC0m26xN
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/MyDrive/Colab Notebooks/Final Dog or cat using cnn'

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from glob import glob

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical

from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint

import cv2

category = ["cats", "dogs"]

EPOCHS = 60
IMGSIZE = 224
CHANNELS = 3 # grayscale
BATCH_SIZE = 128
STOPPING_PATIENCE = 8
VERBOSE = 1
OPTIMIZER = 'adam'
TRAINING_DIR="data/training_set"
TEST_DIR="data/test_set"

generator = ImageDataGenerator(rescale=1./255, 
                               shear_range=0.15, 
                               zoom_range=0.2, 
                               horizontal_flip=True
                              ) 

train_data = generator.flow_from_directory( directory=TRAINING_DIR, 
                                            target_size=(IMGSIZE, IMGSIZE),
                                            color_mode='rgb',
                                            classes=category, 
                                            batch_size=BATCH_SIZE, 
                                            )


test_data = generator.flow_from_directory( directory=TEST_DIR, 
                                           target_size=(IMGSIZE, IMGSIZE), 
                                           color_mode='rgb',
                                           classes=category, 
                                           batch_size=BATCH_SIZE,
                                           shuffle=False
                                           )

model = Sequential()

model.add(Conv2D(16, (3, 3), activation='relu', padding = 'same', input_shape=(IMGSIZE, IMGSIZE, CHANNELS)))
model.add(Conv2D(16, (3, 3), activation='relu',padding = 'same'))
model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))
model.add(BatchNormalization())

model.add(Conv2D(32, (3, 3), activation='relu',padding = 'same'))
model.add(Conv2D(32, (3, 3), activation='relu',padding = 'same'))
model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))
model.add(BatchNormalization())

model.add(Conv2D(64, (3, 3), activation='relu',padding = 'same'))
model.add(Conv2D(64, (3, 3), activation='relu',padding = 'same'))
model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))
model.add(BatchNormalization())

model.add(Conv2D(128, (3, 3), activation='relu',padding = 'same'))
model.add(Conv2D(128, (3, 3), activation='relu',padding = 'same'))
model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))
model.add(BatchNormalization())
model.add(Dropout(0.3))

model.add(Conv2D(256, (3, 3), activation='relu',padding = 'same'))
model.add(Conv2D(256, (3, 3), activation='relu',padding = 'same'))
model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))
model.add(BatchNormalization())
model.add(Dropout(0.3))


model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))


model.add(Dense(2, activation='softmax'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

from tensorflow.keras.utils import plot_model

plot_model(model, show_shapes = True,expand_nested = True,dpi = 80)

es = EarlyStopping(patience=STOPPING_PATIENCE, 
                   monitor='val_accuracy', 
                   mode='max', 
                   verbose=1, 
                   restore_best_weights=True)

checkpoint = ModelCheckpoint(
    'saved-model/best-model', monitor='val_loss', mode='min', 
    save_weights_only=True, save_best_only=True, verbose=1
)

history = model.fit(train_data, 
                    epochs=EPOCHS, 
                    validation_data=test_data,
                    shuffle=True,
                    callbacks=[es,checkpoint])

hist_df = pd.DataFrame(history.history)
hist_df.plot(y=['loss', 'val_loss'], figsize=(30, 10))
plt.xlabel('epoch')
plt.ylabel('loss')
plt.title('Training and Validation loss')
plt.grid(axis='both')
plt.xticks(np.arange(0, 61, 2))
plt.show()

hist_df = pd.DataFrame(history.history)
hist_df.plot(y=['accuracy', 'val_accuracy'], figsize=(30, 10))
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.title('Training and Validation Accuracy')
plt.grid(axis='both')
plt.xticks(np.arange(0,61, 2))
plt.yticks(np.arange(0.5, 1.01, 0.05))
plt.show()

model.load_weights('saved-model/best-model')
train_acc=model.evaluate(train_data)
test_acc = model.evaluate(test_data)

test_paths = np.array(glob(TEST_DIR + '/*/*.jpg'))

ids = np.random.choice(np.arange(len(test_paths)), size=32)


samples = test_paths[ids]

im_test = []
c = 0
for img in samples:
    c = c + 1
    img_path = img
    img_arr = cv2.imread(img_path, cv2.IMREAD_COLOR)
    img_arr = cv2.cvtColor(img_arr,cv2.COLOR_BGR2RGB)
    img_arr = cv2.resize(img_arr, (IMGSIZE, IMGSIZE))
    img_arr = img_arr / 255.0
    im_test.append(img_arr)

    
im_test = np.array(im_test).reshape(-1, IMGSIZE, IMGSIZE,3)
im_pred = model.predict(im_test)

fig , ax = plt.subplots(4, 4, figsize=(30, 25))


for i, axis in enumerate(ax.flat):
    axis.imshow(im_test[i][:, :, 0],cmap='gray')
    pred_class = im_pred[i].argmax()
    pred_prob = im_pred[i].max() * 100
    

    axis.set_title(f'Predict: {category[pred_class]}\n Confidence: {pred_prob:.1f}%', fontsize=18)

# save the model weights
model.save_weights("my_model")

